{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement: **Threat Classification for AtliQ Wildlife Reserve**\n",
        "\n",
        "### Welcome to the AtliQ Wildlife Reserve, a sanctuary where technology helps preserve wildlife. You are tasked with developing AI systems to monitor, classify, and predict behaviors of animals in the sanctuary.\n",
        "\n",
        "\n",
        "**References:**\n",
        "\n",
        "* PyTorch Dataset and Dataloader [link](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
        "* Seaborn Heatmaps [link](https://seaborn.pydata.org/generated/seaborn.heatmap.html)\n"
      ],
      "metadata": {
        "id": "bh8Jc28NWy7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and CUDA"
      ],
      "metadata": {
        "id": "Z5MqurUZXGoU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kq7PLN6WEo3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's do some revision first!\n",
        "\n",
        "**Problem1.** AtliQ Warehouse\n",
        "\n",
        "Your task is to define a simple neural network that will predict whether AtliQ's warehouses are running an optimal stock level for a given product (binary classification). The neural network should include:\n",
        "\n",
        "* An input layer of size 128 (representing features such as sales trends, regional demand, and supplier reliability).\n",
        "* Two hidden layers, each with 64 neurons.\n",
        "* An output layer that predicts the stock status (1 for optimal, 0 for not optimal).\n",
        "\n",
        "\n",
        "**Hint:** Use nn.Sequential to define the network."
      ],
      "metadata": {
        "id": "NXD3uwVpHjMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "   # Code Here\n",
        ")\n",
        "\n",
        "# Print the model structure\n",
        "print(model)"
      ],
      "metadata": {
        "id": "VruFTaiIHm9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pKM7R8qtISyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem2.** Sales data at AtliQ\n",
        "\n",
        "AtliQ's data analytics team has provided sales data in NumPy format for your AI models. The data,\n",
        "\n",
        "` data = np.array([1, 2, 3, 4, 5])`,\n",
        "\n",
        " represents product sales in a given week. Your task is to:\n",
        "\n",
        "Convert this NumPy array into a PyTorch tensor of type float32.\n"
      ],
      "metadata": {
        "id": "_Ye_04NuH5Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a NumPy array\n",
        "data =\n",
        "\n",
        "# Convert the NumPy array to a PyTorch tensor of type float32\n",
        "tensor_data =\n",
        "\n",
        "# Print the tensor\n",
        "print(tensor_data)"
      ],
      "metadata": {
        "id": "KA0qDRm2H9HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oA20Ywx9IT6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem3.** Customer Classification at AtliQ\n",
        "\n",
        "AtliQ's marketing team is running an AI model to classify customers into 3 distinct segments based on purchasing behavior. Your task is to:\n",
        "\n",
        "* Simulate raw logits from the model's output.\n",
        "* Generate random target labels for a 3-class classification task\n",
        "* Compute the classification loss using nn.CrossEntropyLoss\n",
        "\n",
        "**Hint**: Use torch.randint() for generating random target labels and nn.CrossEntropyLoss() for the loss function."
      ],
      "metadata": {
        "id": "GWUBNL9hIE9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = torch.tensor([[1.0, 2.0, 0.5], [1.5, 0.2, 1.7], [0.4, 0.8, 2.1]], dtype=torch.float32)\n",
        "\n",
        "labels = torch.tensor([1, 2, 0], dtype=torch.long)\n",
        "\n",
        "# Define the CrossEntropyLoss function\n",
        "loss_fun = # Code Here\n",
        "\n",
        "# Compute the loss\n",
        "loss = # Code Here\n",
        "\n",
        "print(f\"Cross-Entropy Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "frkwQz0vIGxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wSO1nyKkCKmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task:** Habitat Threat Detector\n",
        "\n",
        "In the sanctuary, camera drones monitor animal habitats for threats like poaching activities or habitat damage. Your task as an AI Engineer is to build an AI system to detect whether an image shows a threat from the provided dataset **(habitat_images_codebasics_DL.csv)**."
      ],
      "metadata": {
        "id": "5cg8Swd2YAWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Overview**\n",
        "\n",
        "The dataset **habitat_images_codebasics_DL.csv** contains the following features:\n",
        "\n",
        "* Image Brightness (float): Represents how bright or dark the image is.\n",
        "* Movement Intensity (float): Measures activity detected in the image.\n",
        "* Number of Shapes Detected (integer): Indicates potential objects in the image.\n",
        "* Noise Level (float): A measure of distortions in the image.\n",
        "* Threat Label (0 or 1): 0 for no threat, 1 for a threat."
      ],
      "metadata": {
        "id": "PIokYWC0YP4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Load and Split the Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "7_9Qhmdfb-i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"habitat_images_codebasics_DL.csv\")\n",
        "\n",
        "# Separate input features and labels\n",
        "X = # Code Here\n",
        "y = # Code Here"
      ],
      "metadata": {
        "id": "Rogs1y3WZetS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_vNDgGL0CgGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Normalize the input feature"
      ],
      "metadata": {
        "id": "BEeQyboLTPp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))"
      ],
      "metadata": {
        "id": "pIGSwZ2BTUbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "B6bZjpy1CNsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3:** Convert to PyTorch tensors\n"
      ],
      "metadata": {
        "id": "GiDwdn7ATcTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Reshape to match the model output"
      ],
      "metadata": {
        "id": "adHSY6CYTlyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4liDHApDCOZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step4**: Perform an **70%-30%** train-validation split."
      ],
      "metadata": {
        "id": "d4qB9eZCTmVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = # Code Here"
      ],
      "metadata": {
        "id": "oW355OZ2TnEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "o8vOlfDOCSP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step5**: Create DataLoader for batch processing"
      ],
      "metadata": {
        "id": "sqR6Q2xXT9kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = # Code Here\n",
        "test_data = # Code Here\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "hfVYt4wRUAgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VEEbzWfpCWJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6:** Define the Neural Network\n",
        "\n",
        "* Input layer with 4 features.\n",
        "* One hidden layer with 8 neurons (ReLU activation).\n",
        "* Output layer with 1 neuron (Sigmoid activation for binary classification)."
      ],
      "metadata": {
        "id": "4MZtV-f_cMi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ThreatDetector(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ThreatDetector, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            # Code Here,    # Input: 4 features, Hidden layer: 8 neurons\n",
        "            # Code Here,          # Activation: ReLU\n",
        "            # Code Here,    # Output: 1 neuron\n",
        "            nn.Sigmoid()        # Activation: Sigmoid (for binary classification)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Instantiate the model\n",
        "model = # Code Here\n"
      ],
      "metadata": {
        "id": "OzjTQoEYcXv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mdGIL4AgCXbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step7**: Define Loss and Optimizer\n",
        "\n",
        "* Optimizer: Adam\n",
        "* Loss: BCE Loss\n",
        "* Learning rate: 0.01"
      ],
      "metadata": {
        "id": "geUtDQ-AUghS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary Cross-Entropy Loss\n",
        "BCE_loss = # Code Here\n",
        "\n",
        "# Adam Optimizer\n",
        "optimizer =# Code Here\n"
      ],
      "metadata": {
        "id": "0lCy2REGUl5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uhvb58nVCY1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8**: Train the Neural Network\n",
        "\n",
        "* Train the model for 20 epochs"
      ],
      "metadata": {
        "id": "VMDovUEJcZe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, BCE_loss, optimizer, epochs=20):\n",
        "    # Code Here\n",
        "\n",
        "            # Forward pass\n",
        "\n",
        "\n",
        "            # Backward pass\n",
        "\n",
        "\n",
        "            # Accumulate loss\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, BCE_loss, optimizer, epochs=)\n"
      ],
      "metadata": {
        "id": "edU_flFQdgMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qGsCOWreCZ2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9:** Evaluate the Model\n",
        "\n",
        "* Calculate the accuracy and loss on a test dataset.\n",
        "* Use a confusion matrix to evaluate the system’s performance."
      ],
      "metadata": {
        "id": "s7YoTEEddiwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    # Code Here\n",
        "\n",
        "    # Convert predictions to binary (threshold = 0.5)\n",
        "    y_pred_binary = # Code Here\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = # Code Here\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = # Code Here\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "id": "rxDluCzUWBls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2inPw3AICa1E"
      }
    }
  ]
}